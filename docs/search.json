[
  {
    "objectID": "posts/ceda-archive/index.html",
    "href": "posts/ceda-archive/index.html",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(bggjphd)\ntheme_set(theme_bggj())"
  },
  {
    "objectID": "posts/ceda-archive/index.html#setup",
    "href": "posts/ceda-archive/index.html#setup",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "Setup",
    "text": "Setup\nThe first things you’re going to need are the following:\n\nA CEDA Archive account\nA CEDA FTP password\nThe location of the files you want to download.\nOn your dataset page, press download and navigate to the subset you want to fetch"
  },
  {
    "objectID": "posts/ceda-archive/index.html#file-location",
    "href": "posts/ceda-archive/index.html#file-location",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "File Location",
    "text": "File Location\nIn my case the 720 files are located at\n\n\nCode\nurl <- \"ftp://ftp.ceda.ac.uk/badc/ukcp18/data/land-cpm/uk/5km/rcp85/01/pr/1hr/v20210615/\""
  },
  {
    "objectID": "posts/ceda-archive/index.html#authentication",
    "href": "posts/ceda-archive/index.html#authentication",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "Authentication",
    "text": "Authentication\nWe’re going to need to input our username and password into the URL to download the data. In order to hide my login info when coding I put it in my R Environment (easy to edit with usethis::edit_r_environ()) and can thus write a function to input it in requests. I never assign my info to variables, but rather just use functions to input them.\n\n\nCode\nuserpwd <- function() {\n  str_c(\n    Sys.getenv(\"CEDA_USR\"), \n    Sys.getenv(\"CEDA_PWD\"), \n    sep = \":\"\n  )\n}\n\n\nNow we can send a request to the FTP server in order to get a list of all the files we want to download\n\n\nCode\nfilenames <- RCurl::getURL(\n  url,\n  userpwd = userpwd(),\n  dirlistonly = TRUE\n)\n\n\nAs you can see below, the result is given to us as one long string.\n\n\nCode\nstringr::str_sub(\n  filenames,\n  start = 1,\n  end = 160\n)\n\n\n[1] \"pr_rcp85_land-cpm_uk_5km_01_1hr_19801201-19801230.nc\\npr_rcp85_land-cpm_uk_5km_01_1hr_19810101-19810130.nc\\npr_rcp85_land-cpm_uk_5km_01_1hr_19810201-19810230.nc\\np\""
  },
  {
    "objectID": "posts/ceda-archive/index.html#cleaning-up-the-file-names",
    "href": "posts/ceda-archive/index.html#cleaning-up-the-file-names",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "Cleaning up the file names",
    "text": "Cleaning up the file names\nWe get a single string with all the file names. It’s easy to split them up into separate strings ands remove the trailing empty line.\n\n\nCode\nfiles <- filenames |>\n  stringr::str_split_1(pattern = \"\\n\")\n\nfiles <- files[-length(files)]\n\nhead(files)\n\n\n[1] \"pr_rcp85_land-cpm_uk_5km_01_1hr_19801201-19801230.nc\"\n[2] \"pr_rcp85_land-cpm_uk_5km_01_1hr_19810101-19810130.nc\"\n[3] \"pr_rcp85_land-cpm_uk_5km_01_1hr_19810201-19810230.nc\"\n[4] \"pr_rcp85_land-cpm_uk_5km_01_1hr_19810301-19810330.nc\"\n[5] \"pr_rcp85_land-cpm_uk_5km_01_1hr_19810401-19810430.nc\"\n[6] \"pr_rcp85_land-cpm_uk_5km_01_1hr_19810501-19810530.nc\""
  },
  {
    "objectID": "posts/ceda-archive/index.html#writing-data-processing-functions",
    "href": "posts/ceda-archive/index.html#writing-data-processing-functions",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "Writing data processing functions",
    "text": "Writing data processing functions\nNow comes the tricky part. We are going to download 720 files (one for each month) that are around 120MB each. If we just download them and keep them on our hard drive that’s going to be upwards of 70GB. Instead of doing that we will use the function process_data() below to do the following:\n\nFor each dataset\n\n\nCreate a temporary file\nDownload the data into the temporary file\nFor each location, throw away all measurements except for the maximum\nCreate a tidy table with information about the coordinates of the location, the max precipitation and the observation date-range\nDelete the temporary file\n\nBefore we can iterate we will need to create a new helper function. Since we will now be using download.file() to download our data sets, we need to input our username and password into the URL. As before, in order to not reveal our information we use functions instead of creating global variables in the environment. Thus we won’t accidentally leak our information when for example taking screenshots.\n\n\nCode\nmake_download_path <- function(filename) {\n  url |>\n    stringr::str_replace(\"//\", stringr::str_c(\"//\", userpwd(), \"@\")) |>\n    stringr::str_c(filename)\n}\n\n\nThe data files are stored in .nc form. The ncdf4 package lets us connect to these kinds of files and pull in the variables we need.\n\n\nCode\nprocess_data <- function(filename) {\n  \n  Sys.sleep(0.1)\n  \n  from_to <- stringr::str_extract_all(filename, \"_[0-9]{8}-[0-9]{8}\")[[1]] |>\n    stringr::str_replace(\"_\", \"\") |>\n    stringr::str_split_1(\"-\")\n  \n  from <- as.Date(from_to[1], format = \"%Y%m%d\")\n  to <- from + lubridate::months(1, abbreviate = FALSE) - lubridate::days(1)\n  \n  tmp <- tempfile()\n  \n  download.file(\n    make_download_path(filename),\n    tmp,\n    mode = \"wb\",\n    quiet = TRUE\n  )\n  \n  temp_d <- ncdf4::nc_open(tmp)\n  \n  max_pr <- ncdf4::ncvar_get(temp_d, \"pr\") |>\n    apply(MARGIN = c(1, 2), FUN = max)\n  \n  lat <- ncdf4::ncvar_get(temp_d, \"latitude\")\n  long <- ncdf4::ncvar_get(temp_d, \"longitude\")\n  \n  out <- tidyr::crossing(\n    proj_x = 1:180,\n    proj_y = 1:244,\n    from_date = from,\n    to_date = to\n  ) |>\n    dplyr::arrange(proj_y, proj_x) |>\n    dplyr::mutate(\n      precip = as.numeric(max_pr),\n      longitude = as.numeric(long),\n      latitude = as.numeric(lat),\n      station = row_number()\n    )\n  \n  out\n}"
  },
  {
    "objectID": "posts/ceda-archive/index.html#putting-it-all-together",
    "href": "posts/ceda-archive/index.html#putting-it-all-together",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "Putting it all together",
    "text": "Putting it all together\nHaving defined our function we throw it into purrr::map_dfr() (map_dfr() tells R that the output should be a dataframe in which the iteration results are concatenated rowwise) for iteration and say yes please to a progress bar. I could have used the furrr package to reduce the time by downloading multiple files in parallel, but I was afraid of getting timed out from the CEDA FTP server so I decided to just be patient.\n\n\nCode\nd <- files |>\n  purrr::map_dfr(process_data, .progress = TRUE)\n\n\nHaving created our dataset we write it out to disk using everyone’s favorite new format parquet. This way we can efficiently query the data without reading it into memory using arrow::open_dataset().\nThis whole process took 3 hours and 21 minutes on my computer. The largest bottleneck by far was downloading the data.\n\n\nCode\nd |>\n  arrow::write_parquet(\"monthly_data.parquet\")"
  },
  {
    "objectID": "posts/ceda-archive/index.html#final-processing",
    "href": "posts/ceda-archive/index.html#final-processing",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "Final processing",
    "text": "Final processing\nI mentioned above that I only needed the yearly data, but currently the dataset contains monthly maxima. Since I might need to do seasonal modeling later in my PhD I decided it would be smart to keep the monthly data, but it’s also very easy to further summarise the data into yearly maxima.\nSince the data for 1980 contain only one month, I decided to not include that year as it is not really a true yearly maximum.\n\n\nCode\nd <- d |>\n  dplyr::mutate(year = lubridate::year(from_date)) |>\n  dplyr::filter(year > 1980) |>\n  dplyr::group_by(year, station, proj_x, proj_y, longitude, latitude) |>\n  dplyr::summarise(\n    precip = max(precip),\n    .groups = \"drop\"\n  )\n\nd |>\n  arrow::write_parquet(\"yearly_data.parquet\")"
  },
  {
    "objectID": "posts/forest-plot-table/index.html",
    "href": "posts/forest-plot-table/index.html",
    "title": "Fetching FTP data from the Ceda Archives",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(bggjphd)\ntheme_set(theme_bggj())\n\n\nFor my PhD modeling I needed to fetch a large amount of data from the CEDA Archive, specifically UKCP Local Projections on a 5km grid over the UK for 1980-2080.\n\n\n\nScreenshot of the data page"
  },
  {
    "objectID": "phd/articles/methods/code/max/index.html",
    "href": "phd/articles/methods/code/max/index.html",
    "title": "The Max Step",
    "section": "",
    "text": "Log likelihood\n\nneg_log_lik_gev_trend <- function(\n    y,\n    t,\n    par,\n    priors,\n    links,\n    t0 = 1981\n) {\n  t <- t - t0\n  \n  mu0 <- exp(par[1])\n  sigma <- exp(par[2] + par[1])\n  xi <- link_shape_inverse(par[3])\n  delta <- link_trend_inverse(par[4])\n  \n  mu <- mu0 * (1 + delta * t)\n  \n  z <- (y - mu) / sigma\n  \n  if (any(1 + xi * z <= 0)) {\n    return(NA)\n  }\n  \n  out <- evd::dgev(\n    x = y,\n    loc = mu,\n    scale = sigma,\n    shape = xi,\n    log = TRUE\n  ) |>\n    sum()\n  \n  prior_likelihood <- priors$location(par[1]) +\n    priors$scale(par[2]) +\n    priors$shape(par[3]) +\n    priors$trend(par[4])\n  \n  out <- out + prior_likelihood\n  \n  -out\n}"
  },
  {
    "objectID": "phd/articles/methods/data/ukcp/index.html",
    "href": "phd/articles/methods/data/ukcp/index.html",
    "title": "UKCP Data",
    "section": "",
    "text": "Code\nlibrary(bggjphd)\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(cowplot)\nlibrary(glue)\ntheme_set(theme_bggj())"
  },
  {
    "objectID": "phd/articles/methods/data/ukcp/index.html#maximum-precipitation",
    "href": "phd/articles/methods/data/ukcp/index.html#maximum-precipitation",
    "title": "UKCP Data",
    "section": "Maximum precipitation",
    "text": "Maximum precipitation\n\n\nCode\np <- full_data |> \n  ggplot(aes(max_precip, y = after_stat(density))) +\n  geom_histogram(bins = 100) +\n  scale_x_continuous(\n    limits = c(0, NA),\n    expand = expansion()\n  ) +\n  scale_y_continuous(\n    expand = expansion()\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Distribution of station-wise maximum precipitation over the period\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/figure1.png\",\n  width = 8, height = 0.621 * 8, scale = 1.3\n)\n\n\n\n\n\nCode\np <- full_data |> \n  ggplot(aes(proj_x, proj_y, fill = max_precip)) +\n  geom_raster(\n    interpolate = TRUE\n  ) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(full_data$proj_x), pretty(full_data$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(full_data$proj_y), pretty(full_data$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  theme(\n    plot.margin = margin(t = 5, r = 25, b = 5, l = 5)\n  ) +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = \"Maximum Precipitation\",\n    title = \"Spatial distribution of maximum precipitation\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/figure2.png\",\n  width = 8, height = 0.621 * 8, scale = 1.3\n)"
  },
  {
    "objectID": "phd/articles/methods/data/ukcp/index.html#minimum-precipitation",
    "href": "phd/articles/methods/data/ukcp/index.html#minimum-precipitation",
    "title": "UKCP Data",
    "section": "Minimum precipitation",
    "text": "Minimum precipitation\n\n\nCode\np <- full_data |> \n  ggplot(aes(min_precip, y = after_stat(density))) +\n  geom_histogram(bins = 100) +\n  scale_x_continuous(\n    limits = c(0, NA),\n    expand = expansion()\n  ) +\n  scale_y_continuous(\n    expand = expansion()\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Distribution of station-wise minimum precipitation over the period\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/figure3.png\",\n  width = 8, height = 0.621 * 8, scale = 1.3\n)\n\n\n\n\n\nCode\np <- full_data |> \n  ggplot(aes(proj_x, proj_y, fill = min_precip)) +\n  geom_raster(\n    interpolate = TRUE\n  ) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(full_data$proj_x), pretty(full_data$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(full_data$proj_y), pretty(full_data$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  theme(\n    # legend.position = \"top\",\n    plot.margin = margin(t = 5, r = 25, b = 5, l = 5)\n  ) +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = \"Minimum Precipitation\",\n    title = \"Spatial distribution of minimum precipitation\"\n  )\nggsave(\n  plot = p,\n  filename = \"Figures/figure4.png\",\n  width = 8, height = 0.621 * 8, scale = 1.3\n)"
  },
  {
    "objectID": "phd/articles/results/max/index.html",
    "href": "phd/articles/results/max/index.html",
    "title": "The Max Step",
    "section": "",
    "text": "In our case we want \\(\\mu\\) to vary with time. If we write \\(y_{it}\\) for the observed hourly maximum at station \\(i\\) during year \\(t\\) we will then have\nwhere\nand"
  },
  {
    "objectID": "phd/articles/results/max/index.html#transformed-parameters",
    "href": "phd/articles/results/max/index.html#transformed-parameters",
    "title": "The Max Step",
    "section": "Transformed parameters",
    "text": "Transformed parameters\nHaving performed the Max step and saved the ML estimates we can easily load them by fetching the object station_estimates. Here we plot the distribution of transformed estimates.\n\\[\\begin{aligned}\n\\psi &= \\log(\\mu) \\\\\n\\tau &= \\log(\\frac{\\sigma}{\\mu}) = \\log(\\sigma) - \\log(\\mu) \\\\\n\\phi &= h(\\xi) \\\\\n\\gamma &= d(\\Delta),\n\\end{aligned}\\]\nwhere the link functions for the shape and trend parameters are defined according to Johannesson et al. (2021)\n\nJohannesson, Árni V., Stefan Siegert, Raphaël Huser, Haakon Bakka, and Birgir Hrafnkelsson. 2021. “Approximate Bayesian Inference for Analysis of Spatio-Temporal Flood Frequency Data,” April. https://doi.org/10.48550/arXiv.1907.04763.\n\\[\\begin{aligned}\nh(\\xi) &= a_\\phi + b_\\phi \\log\\left(-\\log\\left[1 - \\left(\\xi + \\frac12\\right)^{c_\\phi}\\right]\\right) \\\\\nc_\\phi &= 0.8 \\\\\nb_\\phi &= -\\frac{1}{c_\\phi}\\log\\left(1 - \\frac{1}{2^{c_\\phi}}\\right)\\left(1 - \\frac{1}{2^{c_\\phi}}\\right) 2^{c_\\phi - 1} \\\\\na_\\phi &= -b_\\phi \\log\\left(-\\log(1 - \\frac{1}{2^{c_\\phi}})\\right) \\\\\n\n\\newline\n\nd(\\Delta) &= \\frac12 \\delta_0 \\left(\\log(\\delta_0 + \\Delta) - \\log(\\delta_0 - \\Delta_i)\\right) \\\\\n\\delta_0 &= 0.008.\n\\end{aligned}\\]"
  },
  {
    "objectID": "phd/articles/results/max/index.html#distributions",
    "href": "phd/articles/results/max/index.html#distributions",
    "title": "The Max Step",
    "section": "Distributions",
    "text": "Distributions\n\nTransformed Scale\n\n\nCode\nd_prior <- crossing(\n  name = c(\"phi\", \"gamma\"),\n  x = seq(-1, 1, len = 200)\n) |> \n  mutate(\n    x = ifelse(name == \"phi\", x * 0.8, x * 0.01),\n    y = ifelse(name == \"phi\", prior_shape(x) |> exp(), prior_trend(x) |> exp()),\n    y = ifelse(name == \"phi\", y * 6000, y * 0.05)\n  )\n\n\nd |> \n  ggplot(aes(value)) +\n  geom_histogram(bins = 60) +\n  geom_line(\n    data = d_prior,\n    aes(x = x, y = y * 1e3),\n    inherit.aes = F\n  ) +\n  facet_wrap(\"name\", scales = \"free\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Distributions of GEV parameters from Max step\",\n    subtitle = \"The superimposed curves are the implied prior distributions\"\n  )\n\n\n\n\n\n\n\nCode\nd |> \n  pivot_wider() |> \n  select(-station, -proj_x, -proj_y) |> \n  ggpairs(progress = FALSE)\n\n\n\n\n\n\n\nOriginal Scale\n\n\nCode\nd_prior <- crossing(\n  name = c(\"phi\", \"gamma\"),\n  x = seq(-1, 1, len = 200)\n) |> \n  mutate(\n    x = ifelse(name == \"phi\", x * 0.8, x * 0.01),\n    y = ifelse(name == \"phi\", prior_shape(x) |> exp(), prior_trend(x) |> exp()),\n    y = ifelse(name == \"phi\", y * 2000000, y * 20),\n    x = ifelse(name == \"phi\", link_shape_inverse(x), link_trend_inverse(x)),\n    name = ifelse(name == \"phi\", \"xi\", \"delta\")\n  )\n\nd |> \n  pivot_wider() |> \n  mutate(mu = exp(psi),\n         sigma = exp(tau + psi),\n         xi = link_shape_inverse(phi),\n         delta = link_trend_inverse(gamma)) |> \n  select(-psi, -tau, -phi, -gamma, -proj_x, -proj_y) |> \n  pivot_longer(c(-station)) |> \n  mutate(name = fct_relevel(name, \"mu\", \"sigma\", \"xi\", \"delta\")) |> \n  ggplot(aes(value)) +\n  geom_histogram(bins = 100) +\n  geom_line(\n    data = d_prior,\n    aes(x = x, y = y),\n    inherit.aes = F\n  ) +\n  facet_wrap(\"name\", scales = \"free\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Distributions of backtransformed GEV parameters from Max step\",\n    subtitle = \"The superimposed curves are the implied prior distributions\"\n  )\n\n\n\n\n\n\n\nCode\nd |> \n  pivot_wider() |> \n  mutate(mu = exp(psi),\n         sigma = exp(tau + psi),\n         xi = link_shape_inverse(phi),\n         delta = link_trend_inverse(gamma)) |> \n  select(-psi, -tau, -phi, -gamma, -station, -proj_x, -proj_y) |> \n  ggpairs(progress = FALSE)"
  },
  {
    "objectID": "phd/articles/results/max/index.html#spatial-distribution",
    "href": "phd/articles/results/max/index.html#spatial-distribution",
    "title": "The Max Step",
    "section": "Spatial Distribution",
    "text": "Spatial Distribution\n\nLocation\n\n\nCode\nd |> \n  filter(name == \"psi\") |> \n  ggplot(aes(proj_x, proj_y, fill = value)) +\n  geom_raster(interpolate = TRUE) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_x), pretty(d$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_y), pretty(d$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = NULL,\n    title = \"Spatial distribution of Psi\"\n  )\n\n\n\n\n\n\n\nCode\nd |> \n  filter(name == \"psi\") |> \n  ggplot(aes(proj_x, proj_y, fill = exp(value))) +\n  geom_raster(interpolate = TRUE) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_x), pretty(d$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_y), pretty(d$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = NULL,\n    title = \"Spatial distribution of Mu\"\n  )\n\n\n\n\n\n\n\nScale\n\n\nCode\nd |> \n  filter(name == \"tau\") |> \n  ggplot(aes(proj_x, proj_y, fill = value)) +\n  geom_raster(interpolate = TRUE) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_x), pretty(d$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_y), pretty(d$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = NULL,\n    title = \"Spatial distribution of Tau\"\n  )\n\n\n\n\n\n\n\nCode\nd |> \n  pivot_wider() |> \n  mutate(sigma = exp(tau + psi)) |> \n  ggplot(aes(proj_x, proj_y, fill = sigma)) +\n  geom_raster(interpolate = TRUE) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_x), pretty(d$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_y), pretty(d$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = NULL,\n    title = \"Spatial distribution of Sigma\"\n  )\n\n\n\n\n\n\n\nShape\n\n\nCode\nd |> \n  filter(name == \"phi\") |> \n  ggplot(aes(proj_x, proj_y, fill = value)) +\n  geom_raster(interpolate = TRUE) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_x), pretty(d$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_y), pretty(d$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = NULL,\n    title = \"Spatial distribution of Phi\"\n  )\n\n\n\n\n\n\n\nCode\nd |> \n  pivot_wider() |> \n  mutate(xi = link_shape_inverse(phi)) |> \n  ggplot(aes(proj_x, proj_y, fill = xi)) +\n  geom_raster(interpolate = TRUE) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_x), pretty(d$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_y), pretty(d$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = NULL,\n    title = \"Spatial distribution of Xi\"\n  )\n\n\n\n\n\n\n\nTrend\n\n\nCode\nd |> \n  filter(name == \"gamma\") |> \n  ggplot(aes(proj_x, proj_y, fill = value)) +\n  geom_raster(interpolate = TRUE) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_x), pretty(d$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_y), pretty(d$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = NULL,\n    title = \"Spatial distribution of Gamma\"\n  )\n\n\n\n\n\n\n\nCode\nd |> \n  pivot_wider() |> \n  mutate(delta = link_trend_inverse(gamma)) |> \n  ggplot(aes(proj_x, proj_y, fill = delta)) +\n  geom_raster(interpolate = TRUE) +\n  scale_x_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_x), pretty(d$proj_x))\n  ) +\n  scale_y_continuous(\n    expand = expansion(),\n    breaks = c(range(d$proj_y), pretty(d$proj_y))\n  ) +\n  scale_fill_viridis_c() +\n  labs(\n    x = \"X Projection\",\n    y = \"Y Projection\",\n    fill = NULL,\n    title = \"Spatial distribution of Delta\"\n  )"
  },
  {
    "objectID": "phd/articles/results/copula/index.html",
    "href": "phd/articles/results/copula/index.html",
    "title": "T-Copula",
    "section": "",
    "text": "Code\nlibrary(bggjphd)\nlibrary(tidyverse)\nlibrary(progressr)\nlibrary(future)\nlibrary(bayesplot)\nlibrary(GGally)\nlibrary(scales)\nlibrary(cowplot)\nlibrary(kableExtra)\nlibrary(arrow)\nlibrary(tictoc)\nlibrary(broom)\nlibrary(corrr)\nlibrary(patchwork)\ntheme_set(theme_half_open())"
  },
  {
    "objectID": "phd/articles/results/copula/index.html#mean-values",
    "href": "phd/articles/results/copula/index.html#mean-values",
    "title": "T-Copula",
    "section": "Mean values",
    "text": "Mean values\n\n\nCode\nmultivariate <- read_parquet(\"Data/multivariate.parquet\")\n\nplot_dat <- multivariate |> \n  select(station, model_type, type = term, estimate) |> \n  summarise(\n    mean = mean(estimate),\n    sd = sd(estimate),\n    .by = c(type, model_type)\n  ) |> \n  inner_join(\n    neighbor_types,\n    by = \"type\"\n  ) \n\nmax_est <- max(plot_dat$mean, na.rm = T)\nmin_est <- min(plot_dat$mean, na.rm = T)\nscale_size <- max(abs(max_est), abs(min_est), na.rm = T)\nlimits <- c(-1, 1) * scale_size\n\n\np <- plot_dat |> \n  ggplot(aes(diff_x, diff_y, fill = mean)) +\n  geom_raster() + \n  scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = limits, direction = 1) +\n  facet_wrap(\"model_type\") +\n  labs(\n    x = NULL,\n    y = NULL\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/mean_neighbor_effect_multivariate.png\",\n  width = 8, height = 0.621 * 8, scale = 1.2,\n  bg = \"white\"\n)\n\n\n\n\n\nCode\np <- plot_dat |> \n  select(-sd) |> \n  pivot_wider(names_from = model_type, values_from = mean) |> \n  ggplot(aes(mcmc, ml)) +\n  geom_abline(intercept = 0, slope = 1, lty = 2) +\n  geom_point() +\n  labs(\n    x = \"Neighour effect from spatial model\",\n    y = \"Neighbour effect from ML model\",\n    title = \"Comparison of Mean of neighbour effects in ML and MCMC models\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/compare_mean_neighbor_effect_multivariate.png\",\n  width = 8, height = 0.621 * 8, scale = 1.2,\n  bg = \"white\"\n)"
  },
  {
    "objectID": "phd/articles/results/copula/index.html#spatial-distribution",
    "href": "phd/articles/results/copula/index.html#spatial-distribution",
    "title": "T-Copula",
    "section": "Spatial Distribution",
    "text": "Spatial Distribution\n\nMaximum Likelihood\n\n\nCode\nplot_dat <- multivariate |> \n  filter(model_type == \"ml\") |> \n  select(station, type = term, estimate = statistic) |> \n  mutate(\n    estimate = case_when(\n      estimate > quantile(estimate, 0.995) ~ quantile(estimate, 0.995),\n      estimate < quantile(estimate, 0.005) ~ quantile(estimate, 0.005),\n      TRUE ~ estimate\n    ),\n    .by = type\n  ) |> \n  inner_join(\n    stations,\n    by = \"station\"\n  )\n\n\nmax_est <- max(plot_dat$estimate, na.rm = T)\nmin_est <- min(plot_dat$estimate, na.rm = T)\nscale_size <- max(abs(max_est), abs(min_est), na.rm = T)\nlimits <- c(-1, 1) * scale_size\n\n# plot_dat |>\n#   filter(type == \"ww\") |>\n#   ggplot(aes(proj_x, proj_y, fill = estimate)) +\n#   geom_raster(interpolate = TRUE) +\n#   scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = limits) +\n#   facet_wrap(\"type\")\n\nplots <- plot_dat |> \n  mutate(term = type) |> \n  group_by(type) |> \n  group_nest() |> \n  mutate(\n    plots = map(data, \n                function(data, ...) {\n                  data |> \n                    ggplot(aes(proj_x, proj_y, fill = estimate)) +\n                    geom_raster(interpolate = TRUE) +\n                    scale_fill_distiller(\n                      type = \"div\",\n                      palette = \"RdBu\",\n                      limits = limits,\n                      direction = 1\n                    ) +\n                    facet_wrap(\"term\") +\n                    theme_void() +\n                    labs(\n                      fill = \"t-statistic\"\n                    )\n                }\n    )\n  ) |> \n  select(type, plots) |> \n  pivot_wider(names_from = type, values_from = plots)\n\nlayout <- \"\n##A##\n#BCD#\nEF#GH\n#IJK#\n##L##\n\"\n\n\np <- plots$nn[[1]] + \n  plots$nw[[1]] + plots$n[[1]] + plots$ne[[1]] +\n  plots$ww[[1]] + plots$w[[1]] + plots$e[[1]] + plots$ee[[1]] +\n  plots$sw[[1]] + plots$s[[1]] + plots$se[[1]] +\n  plots$ss[[1]] +\n  plot_layout(\n    design = layout, \n    guides = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Spatial distributions of neighbor effects in t-copula (ML Predictions)\",\n    subtitle = \"Shown as t-statistics of linear model coefficients\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/spatial_dist_by_neighbor_type_ml.png\",\n  width = 8, height = 8, scale = 1,\n  bg = \"white\",\n  dpi = 320\n)\n\n\n\n\n\nSpatial Model\n\n\nCode\nplot_dat <- multivariate |> \n  filter(model_type == \"mcmc\") |> \n  select(station, type = term, estimate = statistic) |> \n  mutate(\n    estimate = case_when(\n      estimate > quantile(estimate, 0.995) ~ quantile(estimate, 0.995),\n      estimate < quantile(estimate, 0.005) ~ quantile(estimate, 0.005),\n      TRUE ~ estimate\n    ),\n    .by = type\n  ) |> \n  inner_join(\n    stations,\n    by = \"station\"\n  )\n\n\nmax_est <- max(plot_dat$estimate, na.rm = T)\nmin_est <- min(plot_dat$estimate, na.rm = T)\nscale_size <- max(abs(max_est), abs(min_est), na.rm = T)\nlimits <- c(-1, 1) * scale_size\n\n# plot_dat |>\n#   filter(type == \"ww\") |>\n#   ggplot(aes(proj_x, proj_y, fill = estimate)) +\n#   geom_raster(interpolate = TRUE) +\n#   scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = limits) +\n#   facet_wrap(\"type\")\n\nplots <- plot_dat |> \n  mutate(term = type) |> \n  group_by(type) |> \n  group_nest() |> \n  mutate(\n    plots = map(data, \n                function(data, ...) {\n                  data |> \n                    ggplot(aes(proj_x, proj_y, fill = estimate)) +\n                    geom_raster(interpolate = TRUE) +\n                    scale_fill_distiller(\n                      type = \"div\",\n                      palette = \"RdBu\",\n                      limits = limits,\n                      direction = 1\n                    ) +\n                    facet_wrap(\"term\") +\n                    theme_void() +\n                    labs(\n                      fill = \"t-statistic\"\n                    )\n                }\n    )\n  ) |> \n  select(type, plots) |> \n  pivot_wider(names_from = type, values_from = plots)\n\nlayout <- \"\n##A##\n#BCD#\nEF#GH\n#IJK#\n##L##\n\"\n\n\np <- plots$nn[[1]] + \n  plots$nw[[1]] + plots$n[[1]] + plots$ne[[1]] +\n  plots$ww[[1]] + plots$w[[1]] + plots$e[[1]] + plots$ee[[1]] +\n  plots$sw[[1]] + plots$s[[1]] + plots$se[[1]] +\n  plots$ss[[1]] +\n  plot_layout(\n    design = layout, \n    guides = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Spatial distributions of neighbor effects in t-copula (MCMC Predictions)\",\n    subtitle = \"Shown as t-statistics of linear model coefficients\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/spatial_dist_by_neighbor_type_mcmc.png\",\n  width = 8, height = 8, scale = 1,\n  dpi = 320,\n  bg = \"white\"\n)"
  },
  {
    "objectID": "phd/articles/results/copula/index.html#parameter-correlations",
    "href": "phd/articles/results/copula/index.html#parameter-correlations",
    "title": "T-Copula",
    "section": "Parameter Correlations",
    "text": "Parameter Correlations\n\nMaximum Likelihood\n\n\nCode\nplot_dat <- multivariate |> \n  filter(model_type == \"ml\") |> \n  select(station, type = term, estimate) |> \n  pivot_wider(names_from = type, values_from = estimate) |> \n  ungroup() |> \n  select(-station) |> \n  correlate(method = \"pearson\", use = \"pairwise.complete.obs\", quiet = T) |> \n  pivot_longer(c(-term), names_to = \"term2\", values_to = \"correlation\") |> \n  inner_join(\n    neighbor_types,\n    by = c(\"term2\" = \"type\")\n  )\n\nmax_cor <- max(plot_dat$correlation, na.rm = T)\nmin_cor <- min(plot_dat$correlation, na.rm = T)\nscale_size <- max(abs(max_cor), abs(min_cor), na.rm = T)\nlimits <- c(-1, 1) * scale_size\n\n\n\n\nplots <- plot_dat |> \n  mutate(type = term) |> \n  group_by(type) |> \n  group_nest() |> \n  mutate(\n    plots = map(data, \n                function(data, ...) {\n                  data |> \n                    ggplot(aes(diff_x, diff_y, fill = correlation)) +\n                    geom_raster() +\n                    # scale_fill_viridis_c(guide = guide_colorbar(), limits = limits) +\n                    scale_fill_distiller(\n                      type = \"div\", \n                      palette = \"RdBu\", \n                      limits = limits,\n                      direction = 1\n                    ) +\n                    facet_wrap(\"term\") +\n                    theme_void() \n                }\n    )\n  ) |> \n  select(type, plots) |> \n  pivot_wider(names_from = type, values_from = plots)\n\n\nlayout <- \"\n##A##\n#BCD#\nEF#GH\n#IJK#\n##L##\n\"\n\n\np <- plots$nn[[1]] + \n  plots$nw[[1]] + plots$n[[1]] + plots$ne[[1]] +\n  plots$ww[[1]] + plots$w[[1]] + plots$e[[1]] + plots$ee[[1]] +\n  plots$sw[[1]] + plots$s[[1]] + plots$se[[1]] +\n  plots$ss[[1]] +\n  plot_layout(\n    design = layout, \n    guides = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Correlations between effects of different neighbors (ML predictions)\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/neighbor_type_correlations_ml.png\",\n  width = 8, height = 8, scale = 1,\n  dpi = 320,\n  bg = \"white\"\n)\n\n\n\n\n\nSpatial model\n\n\nCode\nplot_dat <- multivariate |> \n  filter(model_type == \"mcmc\") |> \n  select(station, type = term, estimate) |> \n  pivot_wider(names_from = type, values_from = estimate) |> \n  ungroup() |> \n  select(-station) |> \n  correlate(method = \"pearson\", use = \"pairwise.complete.obs\", quiet = T) |> \n  pivot_longer(c(-term), names_to = \"term2\", values_to = \"correlation\") |> \n  inner_join(\n    neighbor_types,\n    by = c(\"term2\" = \"type\")\n  )\n\nmax_cor <- max(plot_dat$correlation, na.rm = T)\nmin_cor <- min(plot_dat$correlation, na.rm = T)\nscale_size <- max(abs(max_cor), abs(min_cor), na.rm = T)\nlimits <- c(-1, 1) * scale_size\n\n\n\n\nplots <- plot_dat |> \n  mutate(type = term) |> \n  group_by(type) |> \n  group_nest() |> \n  mutate(\n    plots = map(data, \n                function(data, ...) {\n                  data |> \n                    ggplot(aes(diff_x, diff_y, fill = correlation)) +\n                    geom_raster() +\n                    # scale_fill_viridis_c(guide = guide_colorbar(), limits = limits) +\n                    scale_fill_distiller(\n                      type = \"div\", \n                      palette = \"RdBu\", \n                      limits = limits,\n                      direction = 1\n                    ) +\n                    facet_wrap(\"term\") +\n                    theme_void() \n                }\n    )\n  ) |> \n  select(type, plots) |> \n  pivot_wider(names_from = type, values_from = plots)\n\n\nlayout <- \"\n##A##\n#BCD#\nEF#GH\n#IJK#\n##L##\n\"\n\n\np <- plots$nn[[1]] + \n  plots$nw[[1]] + plots$n[[1]] + plots$ne[[1]] +\n  plots$ww[[1]] + plots$w[[1]] + plots$e[[1]] + plots$ee[[1]] +\n  plots$sw[[1]] + plots$s[[1]] + plots$se[[1]] +\n  plots$ss[[1]] +\n  plot_layout(\n    design = layout, \n    guides = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Correlations between effects of different neighbors (MCMC predictions)\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/neighbor_type_correlations_mcmc.png\",\n  width = 8, height = 8, scale = 1,\n  dpi = 320,\n  bg = \"white\"\n)"
  },
  {
    "objectID": "phd/articles/results/copula/index.html#mean-values-1",
    "href": "phd/articles/results/copula/index.html#mean-values-1",
    "title": "T-Copula",
    "section": "Mean values",
    "text": "Mean values\n\n\nCode\nunivariate <- read_parquet(\"Data/univariate.parquet\")\n\nplot_dat <- univariate |> \n  select(station, model_type, type, estimate) |> \n  summarise(\n    mean = mean(estimate),\n    sd = sd(estimate),\n    .by = c(type, model_type)\n  ) |> \n  inner_join(\n    neighbor_types,\n    by = \"type\"\n  ) \n\nmax_est <- max(plot_dat$mean, na.rm = T)\nmin_est <- min(plot_dat$mean, na.rm = T)\nscale_size <- max(abs(max_est), abs(min_est), na.rm = T)\nlimits <- c(0, 1) * scale_size\n\n\np <- plot_dat |> \n  ggplot(aes(diff_x, diff_y, fill = mean)) +\n  geom_raster() + \n  scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = limits, direction = 1) +\n  facet_wrap(\"model_type\")\n\nggsave(\n  plot = p,\n  filename = \"Figures/mean_neighbor_effect_univariate.png\",\n  width = 8, height = 0.621 * 8, scale = 1.2,\n  bg = \"white\"\n)\n\n\n\n\n\nCode\np <- plot_dat |> \n  select(-sd) |> \n  pivot_wider(names_from = model_type, values_from = mean) |> \n  ggplot(aes(mcmc, ml)) +\n  geom_abline(intercept = 0, slope = 1, lty = 2) +\n  geom_point() +\n  labs(\n    x = \"Neighour effect from spatial model\",\n    y = \"Neighbour effect from ML model\",\n    title = \"Comparison of neighbour effects in ML and MCMC models\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/compare_mean_neighbor_effect_univariate.png\",\n  width = 8, height = 0.621 * 8, scale = 1.2,\n  bg = \"white\"\n)"
  },
  {
    "objectID": "phd/articles/results/copula/index.html#spatial-distribution-1",
    "href": "phd/articles/results/copula/index.html#spatial-distribution-1",
    "title": "T-Copula",
    "section": "Spatial Distribution",
    "text": "Spatial Distribution\n\nMaximum Likelihood\n\n\nCode\nplot_dat <- univariate |> \n  filter(model_type == \"ml\") |> \n  select(station, type, estimate = statistic) |> \n  mutate(\n    estimate = case_when(\n      estimate > quantile(estimate, 0.995) ~ quantile(estimate, 0.995),\n      estimate < quantile(estimate, 0.005) ~ quantile(estimate, 0.005),\n      TRUE ~ estimate\n    ),\n    .by = type\n  ) |> \n  inner_join(\n    stations,\n    by = \"station\"\n  )\n\n\nmax_est <- max(plot_dat$estimate, na.rm = T)\nmin_est <- min(plot_dat$estimate, na.rm = T)\nscale_size <- max(abs(max_est), abs(min_est), na.rm = T)\nlimits <- c(0, 1) * scale_size\n\n# plot_dat |>\n#   filter(type == \"ww\") |>\n#   ggplot(aes(proj_x, proj_y, fill = estimate)) +\n#   geom_raster(interpolate = TRUE) +\n#   scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = limits) +\n#   facet_wrap(\"type\")\n\nplots <- plot_dat |> \n  mutate(term = type) |> \n  group_by(type) |> \n  group_nest() |> \n  mutate(\n    plots = map(data, \n                function(data, ...) {\n                  data |> \n                    ggplot(aes(proj_x, proj_y, fill = estimate)) +\n                    geom_raster(interpolate = TRUE) +\n                    # scale_fill_distiller(\n                    #   type = \"div\",\n                    #   palette = \"RdBu\",\n                    #   limits = limits,\n                    #   direction = 1\n                    # ) +\n                    scale_fill_viridis_c(limits = limits) +\n                    facet_wrap(\"term\") +\n                    theme_void() +\n                    labs(\n                      fill = \"t-statistic\"\n                    )\n                }\n    )\n  ) |> \n  select(type, plots) |> \n  pivot_wider(names_from = type, values_from = plots)\n\nlayout <- \"\n##A##\n#BCD#\nEF#GH\n#IJK#\n##L##\n\"\n\n\np <- plots$nn[[1]] + \n  plots$nw[[1]] + plots$n[[1]] + plots$ne[[1]] +\n  plots$ww[[1]] + plots$w[[1]] + plots$e[[1]] + plots$ee[[1]] +\n  plots$sw[[1]] + plots$s[[1]] + plots$se[[1]] +\n  plots$ss[[1]] +\n  plot_layout(\n    design = layout, \n    guides = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Spatial distributions of neighbor effects in t-copula (ML Predictions)\",\n    subtitle = \"Shown as t-statistics of linear model coefficients\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/spatial_dist_by_neighbor_type_ml_univariate.png\",\n  width = 8, height = 8, scale = 1,\n  dpi = 320,\n  bg = \"white\"\n)\n\n\n\n\n\nSpatial Model\n\n\nCode\nplot_dat <- univariate |> \n  filter(model_type == \"mcmc\") |> \n  select(station, type, estimate) |> \n    mutate(\n    estimate = case_when(\n      estimate > quantile(estimate, 0.995) ~ quantile(estimate, 0.995),\n      estimate < quantile(estimate, 0.005) ~ quantile(estimate, 0.005),\n      TRUE ~ estimate\n    ),\n    .by = type\n  ) |> \n  inner_join(\n    stations,\n    by = \"station\"\n  )\n\n\nmax_est <- max(plot_dat$estimate, na.rm = T)\nmin_est <- min(plot_dat$estimate, na.rm = T)\nscale_size <- max(abs(max_est), abs(min_est), na.rm = T)\nlimits <- c(0, 1) * scale_size\n\n# plot_dat |>\n#   filter(type == \"ww\") |>\n#   ggplot(aes(proj_x, proj_y, fill = estimate)) +\n#   geom_raster(interpolate = TRUE) +\n#   scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = limits) +\n#   facet_wrap(\"type\")\n\nplots <- plot_dat |> \n  mutate(term = type) |> \n  group_by(type) |> \n  group_nest() |> \n  mutate(\n    plots = map(data, \n                function(data, ...) {\n                  data |> \n                    ggplot(aes(proj_x, proj_y, fill = estimate)) +\n                    geom_raster(interpolate = TRUE) +\n                    # scale_fill_distiller(\n                    #   type = \"div\",\n                    #   palette = \"RdBu\",\n                    #   limits = limits,\n                    #   direction = 1\n                    # ) +\n                    scale_fill_viridis_c(limits = limits) +\n                    facet_wrap(\"term\") +\n                    theme_void()\n                }\n    )\n  ) |> \n  select(type, plots) |> \n  pivot_wider(names_from = type, values_from = plots)\n\nlayout <- \"\n##A##\n#BCD#\nEF#GH\n#IJK#\n##L##\n\"\n\n\np <- plots$nn[[1]] + \n  plots$nw[[1]] + plots$n[[1]] + plots$ne[[1]] +\n  plots$ww[[1]] + plots$w[[1]] + plots$e[[1]] + plots$ee[[1]] +\n  plots$sw[[1]] + plots$s[[1]] + plots$se[[1]] +\n  plots$ss[[1]] +\n  plot_layout(\n    design = layout, \n    guides = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Spatial distributions of neighbor effects in t-copula (MCMC Predictions)\",\n    subtitle = \"Shown as t-statistics of linear model coefficients\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/spatial_dist_by_neighbor_type_mcmc_univariate.png\",\n  width = 8, height = 8, scale = 1,\n  dpi = 320,\n  bg = \"white\"\n)"
  },
  {
    "objectID": "phd/articles/results/copula/index.html#parameter-correlations-1",
    "href": "phd/articles/results/copula/index.html#parameter-correlations-1",
    "title": "T-Copula",
    "section": "Parameter Correlations",
    "text": "Parameter Correlations\n\nMaximum Likelihood\n\n\nCode\nplot_dat <- univariate |> \n  filter(model_type == \"ml\") |> \n  select(station, type, estimate) |> \n  pivot_wider(names_from = type, values_from = estimate) |> \n  ungroup() |> \n  select(-station) |> \n  correlate(method = \"pearson\", use = \"pairwise.complete.obs\", quiet = T) |> \n  pivot_longer(c(-term), names_to = \"term2\", values_to = \"correlation\") |> \n  inner_join(\n    neighbor_types,\n    by = c(\"term2\" = \"type\")\n  )\n\nmax_cor <- max(plot_dat$correlation, na.rm = T)\nmin_cor <- min(plot_dat$correlation, na.rm = T)\nscale_size <- max(abs(max_cor), abs(min_cor), na.rm = T)\nlimits <- c(0, 1) * scale_size\n\n\n\n\nplots <- plot_dat |> \n  mutate(type = term) |> \n  group_by(type) |> \n  group_nest() |> \n  mutate(\n    plots = map(data, \n                function(data, ...) {\n                  data |> \n                    ggplot(aes(diff_x, diff_y, fill = correlation)) +\n                    geom_raster() +\n                    # scale_fill_viridis_c(guide = guide_colorbar(), limits = limits) +\n                    scale_fill_distiller(\n                      type = \"div\",\n                      palette = \"RdBu\",\n                      limits = limits,\n                      direction = 1\n                    ) +\n                    # scale_fill_viridis_c(limits = limits) +\n                    facet_wrap(\"term\") +\n                    theme_void() \n                }\n    )\n  ) |> \n  select(type, plots) |> \n  pivot_wider(names_from = type, values_from = plots)\n\n\nlayout <- \"\n##A##\n#BCD#\nEF#GH\n#IJK#\n##L##\n\"\n\n\np <- plots$nn[[1]] + \n  plots$nw[[1]] + plots$n[[1]] + plots$ne[[1]] +\n  plots$ww[[1]] + plots$w[[1]] + plots$e[[1]] + plots$ee[[1]] +\n  plots$sw[[1]] + plots$s[[1]] + plots$se[[1]] +\n  plots$ss[[1]] +\n  plot_layout(\n    design = layout, \n    guides = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Correlations between effects of different neighbors (ML predictions)\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/neighbor_type_correlations_ml_univariate.png\",\n  width = 8, height = 8, scale = 1,\n  dpi = 320,\n  bg = \"white\"\n)\n\n\n\n\n\nSpatial model\n\n\nCode\nplot_dat <- univariate |> \n  filter(model_type == \"mcmc\") |> \n  select(station, type, estimate) |> \n  pivot_wider(names_from = type, values_from = estimate) |> \n  ungroup() |> \n  select(-station) |> \n  correlate(method = \"pearson\", use = \"pairwise.complete.obs\", quiet = T) |> \n  pivot_longer(c(-term), names_to = \"term2\", values_to = \"correlation\") |> \n  inner_join(\n    neighbor_types,\n    by = c(\"term2\" = \"type\")\n  )\n\nmax_cor <- max(plot_dat$correlation, na.rm = T)\nmin_cor <- min(plot_dat$correlation, na.rm = T)\nscale_size <- max(abs(max_cor), abs(min_cor), na.rm = T)\nlimits <- c(0, 1) * scale_size\n\n\n\n\nplots <- plot_dat |> \n  mutate(type = term) |> \n  group_by(type) |> \n  group_nest() |> \n  mutate(\n    plots = map(data, \n                function(data, ...) {\n                  data |> \n                    ggplot(aes(diff_x, diff_y, fill = correlation)) +\n                    geom_raster() +\n                    # scale_fill_viridis_c(guide = guide_colorbar(), limits = limits) +\n                    scale_fill_distiller(\n                      type = \"div\",\n                      palette = \"RdBu\",\n                      limits = limits,\n                      direction = 1\n                    ) +\n                    # scale_fill_viridis_c(limits = limits) +\n                    facet_wrap(\"term\") +\n                    theme_void() \n                }\n    )\n  ) |> \n  select(type, plots) |> \n  pivot_wider(names_from = type, values_from = plots)\n\n\nlayout <- \"\n##A##\n#BCD#\nEF#GH\n#IJK#\n##L##\n\"\n\n\np <- plots$nn[[1]] + \n  plots$nw[[1]] + plots$n[[1]] + plots$ne[[1]] +\n  plots$ww[[1]] + plots$w[[1]] + plots$e[[1]] + plots$ee[[1]] +\n  plots$sw[[1]] + plots$s[[1]] + plots$se[[1]] +\n  plots$ss[[1]] +\n  plot_layout(\n    design = layout, \n    guides = \"collect\"\n  ) +\n  plot_annotation(\n    title = \"Correlations between effects of different neighbors (MCMC predictions)\"\n  )\n\nggsave(\n  plot = p,\n  filename = \"Figures/neighbor_type_correlations_mcmc_univariate.png\",\n  width = 8, height = 8, scale = 1,\n  dpi = 320,\n  bg = \"white\"\n)"
  },
  {
    "objectID": "phd/articles/results/spatial/index.html",
    "href": "phd/articles/results/spatial/index.html",
    "title": "The Smooth Step",
    "section": "",
    "text": "Code\nlibrary(bggjphd)\nlibrary(tidyverse)\nlibrary(bayesplot)\nlibrary(posterior)\nlibrary(GGally)\nlibrary(scales)\nlibrary(cowplot)\nlibrary(kableExtra)\nlibrary(arrow)\ntheme_set(theme_bggj())\nThe latent parameters, \\(\\psi\\), \\(\\tau\\), \\(\\phi\\), and \\(\\gamma\\), are given intrinsic random walk spatial priors, for example\n\\[\n\\begin{aligned}\n\\psi &\\sim \\mathcal N(\\mathbf 0, \\tau_\\psi \\cdot Q_u) \\\\\n\\sigma_\\psi &= \\frac{1}{\\sqrt\\tau_\\psi} \\\\\n\\sigma_\\psi &\\sim \\mathrm{Exp}(1)\n\\end{aligned}\n\\]\nHere, \\(Q_u\\) is defined by\n\\[\nQ_u = R \\otimes I + I \\otimes R,\n\\]\nwhere \\(I\\) is the identity matrix and\n\\[\nR = \\begin{bmatrix}\n1 & -1 & & & & & \\\\\n-1 & 2 & -1 & & & & \\\\\n& -1 & 2 & -1 & & & \\\\\n& & \\ddots & \\ddots & \\ddots & & \\\\\n& & &-1 &2 &-1 & \\\\\n& & & & -1 & 1\\\\\n\\end{bmatrix}.\n\\]\nThe results were obtained by running ms_smooth() in parrallel on four cores with four chains each run for 4000 samples. Half of those samples were designated as warm-up and so we have a total of 8000 samples from the posterior."
  },
  {
    "objectID": "phd/articles/results/spatial/index.html#trace-plots",
    "href": "phd/articles/results/spatial/index.html#trace-plots",
    "title": "The Smooth Step",
    "section": "Trace plots",
    "text": "Trace plots\n\n\nCode\ntheta_results |> \n  filter(.chain != 4) |> \n  filter(.iteration > 1) |>\n  mcmc_trace()"
  },
  {
    "objectID": "phd/articles/results/spatial/index.html#autocorrelation-functions",
    "href": "phd/articles/results/spatial/index.html#autocorrelation-functions",
    "title": "The Smooth Step",
    "section": "Autocorrelation functions",
    "text": "Autocorrelation functions\n\n\nCode\ntheta_results |> \n  filter(.iteration > 1) |> \n  mcmc_acf_bar()"
  },
  {
    "objectID": "phd/articles/results/spatial/index.html#acceptance-probability",
    "href": "phd/articles/results/spatial/index.html#acceptance-probability",
    "title": "The Smooth Step",
    "section": "Acceptance probability",
    "text": "Acceptance probability\n\n\nCode\ntheta_results |> \n  subset_draws(\"theta[1]\") |> \n  as_tibble() |> \n  rename(value = \"theta[1]\") |> \n  group_by(.chain) |> \n  mutate(accept = 1 * (value != lag(value))) |> \n  ungroup() |> \n  ggplot(aes(.iteration, accept, group = .chain)) +\n  geom_smooth(method = \"loess\", span = 0.3, se = 0) +\n  scale_x_continuous(\n    expand = expansion()\n  ) +\n  scale_y_continuous(\n    breaks = pretty_breaks(5),\n    labels = label_percent(),\n    expand = expansion()\n  ) +\n  theme(\n    plot.margin = margin(t = 5, r = 35, b = 5, l = 5)\n  ) +  \n  coord_cartesian(ylim = c(0, 1)) +\n  labs(\n    x = \"Iteration\",\n    y = \"Acceptance probability\",\n    title = \"Acceptance probability for theta[1]\"\n  )"
  },
  {
    "objectID": "phd/articles/results/spatial/index.html#hyperpriors",
    "href": "phd/articles/results/spatial/index.html#hyperpriors",
    "title": "The Smooth Step",
    "section": "Hyperpriors",
    "text": "Hyperpriors\n\nLog precision scale\n\n\nCode\ntheta_results |> \n  filter(.iteration > 1) |> \n  summarise_draws() |> \n  kable(digits = 3) |> \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\n\n \n  \n    variable \n    mean \n    median \n    sd \n    mad \n    q5 \n    q95 \n    rhat \n    ess_bulk \n    ess_tail \n  \n \n\n  \n    theta[1] \n    6.247 \n    6.247 \n    0.020 \n    0.022 \n    6.215 \n    6.282 \n    1.068 \n    41.341 \n    55.597 \n  \n  \n    theta[2] \n    5.345 \n    5.345 \n    0.019 \n    0.022 \n    5.315 \n    5.375 \n    1.056 \n    30.657 \n    53.149 \n  \n  \n    theta[3] \n    6.193 \n    6.192 \n    0.027 \n    0.027 \n    6.151 \n    6.243 \n    1.141 \n    16.002 \n    16.160 \n  \n  \n    theta[4] \n    15.850 \n    15.851 \n    0.045 \n    0.047 \n    15.775 \n    15.923 \n    1.172 \n    14.069 \n    65.501 \n  \n\n\n\n\n\n\n\nCode\ntheta_results |> \n  filter(.iteration > 1) |> \n  mcmc_hist_by_chain(\n  )\n\n\n\n\n\n\n\nOn standard deviation scale\n\n\nCode\ntheta_results |> \n  filter(.iteration > 1) |> \n  summarise_draws() |> \n  kable(digits = 3) |> \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\n\n \n  \n    variable \n    mean \n    median \n    sd \n    mad \n    q5 \n    q95 \n    rhat \n    ess_bulk \n    ess_tail \n  \n \n\n  \n    theta[1] \n    6.247 \n    6.247 \n    0.020 \n    0.022 \n    6.215 \n    6.282 \n    1.068 \n    41.341 \n    55.597 \n  \n  \n    theta[2] \n    5.345 \n    5.345 \n    0.019 \n    0.022 \n    5.315 \n    5.375 \n    1.056 \n    30.657 \n    53.149 \n  \n  \n    theta[3] \n    6.193 \n    6.192 \n    0.027 \n    0.027 \n    6.151 \n    6.243 \n    1.141 \n    16.002 \n    16.160 \n  \n  \n    theta[4] \n    15.850 \n    15.851 \n    0.045 \n    0.047 \n    15.775 \n    15.923 \n    1.172 \n    14.069 \n    65.501 \n  \n\n\n\n\n\n\n\nCode\ntheta_results |> \n  filter(.iteration > 1) |> \n  mcmc_hist_by_chain(\n    transformations = function(x) exp(-x/2)\n  )"
  },
  {
    "objectID": "phd/articles/results/spatial/index.html#gev-parameters",
    "href": "phd/articles/results/spatial/index.html#gev-parameters",
    "title": "The Smooth Step",
    "section": "GEV Parameters",
    "text": "GEV Parameters\n\nComparing ML and MCMC estimates\n\n\nCode\nstation_results |> \n  pivot_longer(c(ml_estimate, mcmc_mean)) |> \n  mutate(\n    variable = fct_relevel(\n      factor(variable),\n      \"psi\", \"tau\", \"phi\", \"gamma\"\n    ),\n    name = fct_recode(\n      factor(name),\n      \"Maximum Likelihood\" = \"ml_estimate\",\n      \"Posterior Mean\" = \"mcmc_mean\"\n    )\n  ) |> \n  ggplot(aes(value)) +\n  geom_histogram() +\n  facet_wrap(vars(variable, name), ncol = 2, scales = \"free_x\") +\n  theme(\n    axis.line.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Distributions of station parameters from ML and MCMC\"\n  )\n\n\n\n\n\n\n\nCode\nstation_results |> \n  ggplot(aes(ml_estimate, mcmc_mean)) +\n  geom_abline(intercept = 0, slope = 1, lty = 2) +\n  geom_point(alpha = 0.1) +\n  facet_wrap(\"variable\", scales = \"free\") +\n  labs(\n    x = \"ML Estimate (Max step)\",\n    y = \"Posterior Mean (Smooth step)\",\n    title = \"Comparing estimates from the Max and the Smooth steps\"\n  )\n\n\n\n\n\n\n\nCode\nstation_results |> \n  pivot_longer(c(ml_estimate, mcmc_mean)) |> \n  pivot_wider(names_from = variable) |> \n  mutate(\n    mu = exp(psi),\n    sigma = exp(psi + tau),\n    xi = link_shape_inverse(phi),\n    delta = link_trend_inverse(gamma)\n  ) |> \n  select(-(gamma:tau)) |> \n  pivot_longer(c(mu:delta), names_to = \"variable\") |> \n  pivot_wider() |> \n  ggplot(aes(ml_estimate, mcmc_mean)) +\n  geom_abline(intercept = 0, slope = 1, lty = 2) +\n  geom_point(alpha = 0.1) +\n  facet_wrap(\"variable\", scales = \"free\") +\n  labs(\n    x = \"ML Estimate (Max step)\",\n    y = \"Posterior Mean (Smooth step)\",\n    title = \"Comparing estimates from the Max and the Smooth steps\"\n  )\n\n\n\n\n\n\n\nSpatial Distributions\n\n\nCode\nproj_plot <- function(data) {\n  \n  title <- str_c(\n    \"Spatial distribution of estimates for \", unique(data$variable)\n  )\n  \n  plot_dat <- data |> \n    pivot_longer(c(ml_estimate, mcmc_mean)) |> \n    mutate(\n      name = fct_recode(\n        factor(name),\n        \"Maximum Likelihood\" = \"ml_estimate\",\n        \"Posterior Mean\" = \"mcmc_mean\"\n      )\n    ) |> \n    group_by(name) |> \n    mutate(\n      value = (value - mean(value)) / sd(value)\n    ) |> \n    ungroup() |> \n    mutate(\n      value = case_when(\n        name == \"Posterior Mean\" ~ value,\n        value < quantile(value, 0.0025) ~ quantile(value, 0.0025),\n        value > quantile(value, 0.9975) ~ quantile(value, 0.9975),\n        TRUE ~ value\n      )\n    )\n  \n  min_val <- min(plot_dat$value)\n  max_val <- max(plot_dat$value)\n  \n  lim_range <- max(abs(min_val), abs(max_val))\n  \n  limits <- c(-1, 1) * lim_range\n  \n  plot_dat |> \n    ggplot(aes(proj_x, proj_y)) +\n    geom_raster(aes(fill = value)) +\n    scale_fill_viridis_c(limits = limits) +\n    facet_wrap(\"name\", nrow = 1) +\n    coord_cartesian(expand = FALSE) +\n    labs(\n      title = title,\n      fill = NULL,\n      x = \"X projection\",\n      y = \"Y projection\"\n    )\n}\n\n\n\nLocation\n\npsi\n\n\nCode\nstation_results |> \n  filter(variable == \"psi\") |> \n  proj_plot()\n\n\n\n\n\n\n\nmu\n\n\nCode\nstation_results |> \n  filter(variable == \"psi\") |> \n  mutate(variable = \"mu\") |> \n  mutate_at(vars(ml_estimate, mcmc_mean), exp) |> \n  proj_plot()\n\n\n\n\n\n\n\n\nScale\n\ntau\n\n\nCode\nstation_results |> \n  filter(variable == \"tau\") |> \n  proj_plot()\n\n\n\n\n\n\n\nsigma\n\n\nCode\nstation_results |> \n  filter(variable %in% c(\"tau\", \"psi\")) |> \n  pivot_longer(c(ml_estimate, mcmc_mean)) |> \n  pivot_wider(names_from = variable, values_from = value) |> \n  mutate(sigma = exp(tau + psi)) |> \n  select(-psi, -tau) |> \n  pivot_longer(c(sigma), names_to = \"variable\", values_to = \"value\") |> \n  pivot_wider() |> \n  proj_plot()\n\n\n\n\n\n\n\n\nShape\n\nphi\n\n\nCode\nstation_results |> \n  filter(variable == \"phi\") |> \n  proj_plot()\n\n\n\n\n\n\n\nxi\n\n\nCode\nstation_results |> \n  filter(variable == \"phi\") |> \n  mutate(variable = \"xi\") |> \n  mutate_at(\n    vars(mcmc_mean, ml_estimate),\n    link_shape_inverse\n  ) |> \n  proj_plot()\n\n\n\n\n\n\n\n\nTrend\n\ngamma\n\n\nCode\nstation_results |> \n  filter(variable == \"gamma\") |> \n  proj_plot()\n\n\n\n\n\n\n\nDelta\n\n\nCode\nstation_results |> \n  filter(variable == \"gamma\") |> \n  mutate(variable = \"delta\") |> \n  mutate_at(\n    vars(mcmc_mean, ml_estimate),\n    link_trend_inverse\n    ) |> \n  proj_plot()"
  },
  {
    "objectID": "phd/index.html",
    "href": "phd/index.html",
    "title": "About my PhD",
    "section": "",
    "text": "I’m developing and maintaining this part of my page to go along with my PhD studies for reproducibility and to held me keep my sanity intact for the next years.\nThe main gist of my PhD research will be adding to the Max-and-Smooth method by Hrafnkelsson et al. (2020).\n\nHrafnkelsson, Birgir, Stefan Siegert, Raphaël Huser, Haakon Bakka, and Árni V. Jóhannesson. 2020. “Max-and-Smooth: A Two-Step Approach for Approximate Bayesian Inference in Latent Gaussian Models.” arXiv. https://doi.org/10.48550/arXiv.1907.11969."
  },
  {
    "objectID": "phd/index.html#r-package-on-github",
    "href": "phd/index.html#r-package-on-github",
    "title": "About my PhD",
    "section": "R package on Github",
    "text": "R package on Github\nI’ve put the code and data for any modeling into an R package, bggjphd, which I keep up to date on Github"
  },
  {
    "objectID": "phd/index.html#docker-container",
    "href": "phd/index.html#docker-container",
    "title": "About my PhD",
    "section": "Docker Container",
    "text": "Docker Container\nFor reproducibility I keep a Docker container on Docker Hub that sets up an R environment and all the packages needed to run code from the bggjphd package."
  },
  {
    "objectID": "phd/index.html#data",
    "href": "phd/index.html#data",
    "title": "About my PhD",
    "section": "Data",
    "text": "Data\n\nUKCP\nUKCP Data\nGather data on hourly precipitation"
  },
  {
    "objectID": "phd/index.html#models",
    "href": "phd/index.html#models",
    "title": "About my PhD",
    "section": "Models",
    "text": "Models\n\nMaximum Likelihood Estimation\n\n\nSpatial Smoothing of MLEs"
  },
  {
    "objectID": "talks/hi-vefur/index.html",
    "href": "talks/hi-vefur/index.html",
    "title": "Interview on the University website",
    "section": "",
    "text": "Find the iterview here"
  },
  {
    "objectID": "talks/databeers_2022_09_16/index.html",
    "href": "talks/databeers_2022_09_16/index.html",
    "title": "Databeers #2",
    "section": "",
    "text": "The presentations were in the PechaKucha format:\n\n20 slides\n20 seconds per slide\n\n\n\nLink to the slides in full size"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bggj",
    "section": "",
    "text": "Fetching FTP data from the Ceda Archives\n\n\nUsing R and FTP to programmatically fetch a large amount of data for processing\n\n\n\n\nenglish\n\n\nR\n\n\nphd\n\n\nbig data\n\n\nscraping\n\n\n\n\nFor my PhD modeling I needed to fetch a large amount of data from the CEDA Archive, specifically I use hourly precipitation projections from UKCP Local Projections on a 5km grid over the UK for 1980-2080. The hourly precipitation projections are stored in 720 files that are all approximately 120mb to 130mb. Here I write out my processing in case someone needs help with doing something similar.\n\n\n\n\n\n\nJun 28, 2022\n\n\nBrynjólfur Gauti Guðrúnar Jónsson\n\n\n\n\n\n\n  \n\n\n\n\nForest Plots with Built-In Tables\n\n\nCreating forest plots with coefficient tables in ggplot2 with cowplot\n\n\n\n\nenglish\n\n\nR\n\n\nplots\n\n\ntutorial\n\n\n\n\nI’ve seen this kind of figure poking around, but I didn’t really think about them until the other day I was asked about how to make one in R. Here I will walk through making one of these plots using the ggplot2 and cowplot packages.\n\n\n\n\n\n\nJun 28, 2022\n\n\nBrynjólfur Gauti Guðrúnar Jónsson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Brynjólfur Gauti Guðrúnar Jónsson",
    "section": "",
    "text": "I am a statistics PhD student at the University of Iceland researching improved 21st century projections of sub-daily extreme precipitation by spatio-temporal recalibration. I also teach Statistical consulting and work at The Icelandic Heart Association."
  },
  {
    "objectID": "about.html#talks-interviews-etc.",
    "href": "about.html#talks-interviews-etc.",
    "title": "Brynjólfur Gauti Guðrúnar Jónsson",
    "section": "Talks, interviews etc.",
    "text": "Talks, interviews etc.\n\n\n\n\n\n\n\n\n\n\nDatabeers #2\n\n\nI gave a talk at the 2nd Databeers event hosted by Lucinity. There I talked about open data and helping people make sense of official or press statements by putting them…\n\n\n\n\n\n\nSep 16, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterview on the University website\n\n\nHalldór Marteinsson interviewed me for the University of Iceland website about statistics, covid-19 predictions and more.\n\n\n\n\n\n\nDec 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStanCon2020: COVID-19 Prediction Model\n\n\nI gave a talk about the statistical methodology behind the prediction model used by the Icelandic government during the first wave of the COVID-19 pandemic.\n\n\n\n\n\n\nAug 13, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  }
]